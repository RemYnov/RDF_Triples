name: Spark Script Integrations
on: [push]
jobs:
  install-dependencies:
    name: Install dependencies
    runs-on: ubuntu-latest
    if: "!contains(github.event.head_commit.message, '[skip ci]')"
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Install Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      - name: Cache requirements
        id: cache-deps
        uses: actions/cache@v2
        env:
          cache-name: sparkWorkspaceWithPytest
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ env.cache-name }}-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip- 

      - if: steps.cache-deps.outputs.cache-hit != 'true'
        name: Install dependencies (Cache enabled)
        run: pip install -r requirements.txt

      - name: Run pytests
        run: |
          flake8 logs_management.py
          pytest